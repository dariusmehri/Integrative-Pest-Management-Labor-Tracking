{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23401edf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-12 11:32:17.025072\n",
      "Import packages\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import datetime\n",
    "print (str(datetime.datetime.today() ) )\n",
    "\n",
    "print (\"Import packages\")\n",
    "#pip install cx_Oracle\n",
    "#pip install sqlalcheny\n",
    "#Download Oracle- https://www.oracle.com/database/technologies/instant-client/downloads.html\n",
    "#Connect to cx_Oracle and import packages\n",
    "import cx_Oracle\n",
    "\n",
    "#create path to downloaded oracle files and initiate\n",
    "cx_Oracle.init_oracle_client(lib_dir=r\"C:\\Oracle\\instantclient_21_9\")\n",
    "\n",
    "import sqlalchemy\n",
    "from sqlalchemy.schema import CreateIndex\n",
    "from sqlalchemy import Table, Column, Integer, Numeric,String, ForeignKey\n",
    "from sqlalchemy import MetaData\n",
    "from sqlalchemy import insert\n",
    "metadata= MetaData()\n",
    "\n",
    "from sqlalchemy.engine import create_engine\n",
    "\n",
    "\n",
    "print (\"DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2781853",
   "metadata": {},
   "source": [
    "### Import Labor Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d395e3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import labor transactions\n",
      "2023-10-12\n",
      "2308419\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "path = \"\"\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "print (\"Import labor transactions\")\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "import datetime\n",
    "print (str(datetime.datetime.today()).split()[0] )\n",
    "\n",
    "\n",
    "#from datetime import datetime\n",
    "#print (start )\n",
    "\n",
    "DIALECT = 'oracle'\n",
    "SQL_DRIVER = 'cx_oracle'\n",
    "USERNAME = '' #enter your username\n",
    "PASSWORD = '' #enter your password\n",
    "#HOST = 'exadm1-scan' #enter the oracle db host url\n",
    "HOST = '' #enter the oracle db host url\n",
    "\n",
    "PORT = 1521 # enter the oracle port number\n",
    "SERVICE = 'maxdb' # enter the oracle db service name\n",
    "ENGINE_PATH = DIALECT + '+' + SQL_DRIVER + '://' + USERNAME + ':' + PASSWORD +'@' + HOST + ':' + str(PORT) + '/?service_name=' + SERVICE\n",
    "\n",
    "engine = create_engine(ENGINE_PATH)\n",
    "\n",
    "\n",
    "labtrans_query = \"\"\"\n",
    "\n",
    "select labtrans.LABORCODE,\n",
    "       labtrans.ENTERDATE,\n",
    "       labtrans.REFWO,\n",
    "       labtrans.TRANSTYPE,\n",
    "       labtrans.startdatetime,\n",
    "       labtrans.finishdatetime,\n",
    "       labtrans.location\n",
    "\n",
    "       \n",
    "from Maximo.labtrans labtrans\n",
    "\n",
    "--WHERE TRUNC(labtrans.enterdate) >= sysdate - interval '1' year AND (labtrans.transtype = 'WORKWITHSEQ' OR labtrans.transtype = 'WORK')\n",
    "WHERE labtrans.enterdate >= '01-JAN-2023'  AND (labtrans.transtype = 'WORKWITHSEQ' OR labtrans.transtype = 'WORK' OR labtrans.transtype = 'NOBLDGACCESS' OR labtrans.transtype = 'RESREFUSED' OR labtrans.transtype ='RESNOTHOME' OR labtrans.transtype ='UNFOUNDED' )\n",
    "\n",
    "\"\"\"\n",
    "#(labtrans.enterdate >= '01-JAN-2022')\n",
    "\n",
    "#WHERE TRUNC(xrf_det.entrydate) >= sysdate - interval '1' year AND xrf_det.finalclassification = 'Positive' AND xrf_det.side != 'Calibrate' AND xrf_det.side != 'CALIBRATE'\n",
    "#(labtrans.enterdate >= '12-JAN-2023')\n",
    "#(labtrans.enterdate >= '01-JAN-2022' AND labtrans.enterdate <= '1-MAR-2022')\n",
    "\n",
    "\n",
    "\n",
    "dl = pd.read_sql_query(labtrans_query, engine)\n",
    "\n",
    "print (len(dl))\n",
    "\n",
    "print (\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "709df81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dl.to_csv( path + \"Labor Transactions 1_1_23-10_12_23.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0862661b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160067\n"
     ]
    }
   ],
   "source": [
    "dl2 = dl.copy()\n",
    "dl1 = pd.read_csv(path + \"Labor Transactions 2022.csv\")\n",
    "\n",
    "frames = [dl1, dl2]\n",
    "\n",
    "dl = pd.concat(frames)\n",
    "\n",
    "print (len(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bd718de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5160067\n",
      "unfounded 359174\n",
      "res refused 167133\n",
      "res not home 555342\n",
      "no bldg access 6244\n"
     ]
    }
   ],
   "source": [
    "print (len(dl))\n",
    "\n",
    "a = dl[dl[\"transtype\"] == \"UNFOUNDED\"]\n",
    "print (\"unfounded\", len(a))\n",
    "\n",
    "a = dl[dl[\"transtype\"] == \"RESREFUSED\"]\n",
    "print (\"res refused\", len(a))\n",
    "\n",
    "a = dl[dl[\"transtype\"] == \"RESNOTHOME\"]\n",
    "print (\"res not home\", len(a))\n",
    "\n",
    "a = dl[dl[\"transtype\"] == \"NOBLDGACCESS\"]\n",
    "print (\"no bldg access\", len(a))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbc9ab4",
   "metadata": {},
   "source": [
    "### Import Work Orders to get wonum to subset labor trans and Insert Other Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96abc043",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-12 12:04:55.622167\n",
      "Import work orders\n",
      "230134\n",
      "117354\n",
      "117354\n",
      "115026\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import datetime\n",
    "print (str(datetime.datetime.today()) )\n",
    "\n",
    "\n",
    "print (\"Import work orders\")\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "\n",
    "DIALECT = 'oracle'\n",
    "SQL_DRIVER = 'cx_oracle'\n",
    "USERNAME = '' #enter your username\n",
    "PASSWORD = '' #enter your password\n",
    "#HOST = 'exadm1-scan' #enter the oracle db host url\n",
    "HOST = '' #enter the oracle db host url\n",
    "\n",
    "PORT = 1521 # enter the oracle port number\n",
    "SERVICE = 'maxdb' # enter the oracle db service name\n",
    "ENGINE_PATH = DIALECT + '+' + SQL_DRIVER + '://' + USERNAME + ':' + PASSWORD +'@' + HOST + ':' + str(PORT) + '/?service_name=' + SERVICE\n",
    "\n",
    "engine = create_engine(ENGINE_PATH)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "workorder_query = \"\"\"\n",
    "\n",
    "select max_wo.worktype,\n",
    "       max_wo.problemcode,\n",
    "       max_wo.failurecode,\n",
    "       max_wo.wonum,\n",
    "       max_wo.parent,\n",
    "       TRUNC(max_wo.reportdate) AS report_date,\n",
    "       max_wo.status,\n",
    "       TRUNC(max_wo.statusdate) AS status_date,\n",
    "       max_wo.location,\n",
    "       max_wo.haschildren,\n",
    "       max_wo.OWNERGROUP,\n",
    "       max_wo.ACTSTART,\n",
    "       max_wo.ACTFINISH,\n",
    "       max_wo.ZZPESTSENSITIVE,\n",
    "       max_wo.ZZCRAFT,\n",
    "       max_wo.JPNUM\n",
    "       \n",
    "from Maximo.workorder max_wo\n",
    "\n",
    "--WHERE TRUNC(max_wo.reportdate) >= sysdate - interval '1' year AND max_wo.status = 'CLOSE' AND max_wo.failurecode = 'EXTERMINATION' AND max_wo.worktype = 'CM' \n",
    "\n",
    "WHERE  max_wo.reportdate >= '01-JAN-2023' AND max_wo.status = 'CLOSE' AND max_wo.failurecode = 'EXTERMINATION' AND max_wo.worktype = 'CM' \n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#(max_wo.reportdate >= '01-JAN-2022')\n",
    "#(max_wo.reportdate >= '01-JAN-2022' AND max_wo.reportdate <= '1-MAR-2022')\n",
    "\n",
    "df = pd.read_sql_query(workorder_query, engine)\n",
    "\n",
    "print (len(df))\n",
    "df = df[pd.notnull(df['actstart'])]\n",
    "print (len(df))\n",
    "\n",
    "\n",
    "#print (\"Subset for closed work orders\")\n",
    "#print (len(df))\n",
    "#df = df[df[\"status\"] == \"CLOSE\"]\n",
    "#df = df[df[\"status\"] == \"APPR\"]\n",
    "\n",
    "#subsetlist = [\"CLOSE\", \"APPR\"]\n",
    "\n",
    "#df = df[df['status'].isin(subsetlist)].reset_index(drop=True)\n",
    "\n",
    "print (len(df))\n",
    "df = df[df[\"jpnum\"] == 'M10353']\n",
    "df = df[df[\"zzcraft\"] == 'EXTERMIN']\n",
    "print (len(df))\n",
    "\n",
    "print (\"DONE\")\n",
    "\n",
    "#print (test_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "35054a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv(path + \"Work Orders 1_1_23-10_12_23.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4fb031a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "254880\n"
     ]
    }
   ],
   "source": [
    "df2 = df.copy()\n",
    "df1 = pd.read_csv(path + \"Work Orders 2022.csv\")\n",
    "\n",
    "frames = [df1, df2]\n",
    "\n",
    "df = pd.concat(frames)\n",
    "\n",
    "print (len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85d6170",
   "metadata": {},
   "source": [
    "Subset Labor Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf031ac7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-12 12:10:05.363668\n",
      "Subset Labor Transactions\n",
      "5160067\n",
      "347414\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "print (str(datetime.datetime.today()) )\n",
    "\n",
    "print (\"Subset Labor Transactions\")\n",
    "\n",
    "df[\"wonum\"] = df[\"wonum\"].astype(str).map(str.strip)\n",
    "dl['refwo'] = dl['refwo'].astype(str).map(str.strip)\n",
    "\n",
    "df = df.reset_index(drop=True)\n",
    "dflist = df[\"wonum\"].tolist()\n",
    "\n",
    "print (len(dl))\n",
    "\n",
    "dl2 = dl[dl['refwo'].isin(dflist)].reset_index(drop=True)\n",
    "\n",
    "print (len(dl2))\n",
    "\n",
    "print (\"DONE\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35073521",
   "metadata": {},
   "source": [
    "### Insert Work Order Fields into Labor Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "406d91c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-12 12:10:28.351136\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "print (str(datetime.datetime.today()) )\n",
    "\n",
    "\n",
    "dftypes = [\"failurecode\", \"problemcode\", \"ownergroup\", \"zzcraft\"]\n",
    "\n",
    "for d in dftypes:\n",
    "    dfDic = df.set_index('wonum')[d].to_dict()\n",
    "    dl2[d] = dl2[\"refwo\"].map(dfDic)\n",
    "\n",
    "print (\"DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e215d3",
   "metadata": {},
   "source": [
    "### Import Person Data and Merge with Labor Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "35ff5be4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Import person data\n",
      "2023-10-12 12:10:43.052673\n",
      "DONE\n",
      "2023-10-12 12:10:54.646647\n",
      "347414\n",
      "347414\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "print (\"Import person data\")\n",
    "print (str(datetime.datetime.today()) )\n",
    "\n",
    "\n",
    "#from datetime import datetime\n",
    "#print (start )\n",
    "\n",
    "DIALECT = 'oracle'\n",
    "SQL_DRIVER = 'cx_oracle'\n",
    "USERNAME = '' #enter your username\n",
    "PASSWORD = '' #enter your password\n",
    "#HOST = 'exadm1-scan' #enter the oracle db host url\n",
    "HOST = '' #enter the oracle db host url\n",
    "\n",
    "PORT = 1521 # enter the oracle port number\n",
    "SERVICE = 'maxdb' # enter the oracle db service name\n",
    "ENGINE_PATH = DIALECT + '+' + SQL_DRIVER + '://' + USERNAME + ':' + PASSWORD +'@' + HOST + ':' + str(PORT) + '/?service_name=' + SERVICE\n",
    "\n",
    "engine = create_engine(ENGINE_PATH)\n",
    "\n",
    "\n",
    "person_query = \"\"\"\n",
    "\n",
    "select *  \n",
    "       \n",
    "from Maximo.person \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#WHERE TRUNC(xrf_det.entrydate) >= sysdate - interval '1' year AND xrf_det.finalclassification = 'Positive' AND xrf_det.side != 'Calibrate' AND xrf_det.side != 'CALIBRATE'\n",
    "\n",
    "\n",
    "dp = pd.read_sql_query(person_query, engine)\n",
    "dp = dp[[\"personid\", \"status\", \"displayname\",\"firstname\",\"lastname\",\"department\",\"title\", \"zzhrtitle\", \"hiredate\", \"terminationdate\"]]\n",
    "dp[\"personid\"] = dp[\"personid\"].astype(str).map(str.strip)\n",
    "dp = dp.rename(columns={'personid': 'laborcode'})\n",
    "\n",
    "print (\"DONE\")\n",
    "\n",
    "import datetime\n",
    "print (str(datetime.datetime.today()) )\n",
    "\n",
    "\n",
    "dl2[\"laborcode\"] = dl2[\"laborcode\"].astype(str).map(str.strip)\n",
    "print (len(dl2))\n",
    "dl2 = pd.merge(dl2, dp, how='left', on=['laborcode'])\n",
    "print (len(dl2))\n",
    "\n",
    "print (\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e8ea1663",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dl2.to_csv(path + \"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca90b818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "379\n"
     ]
    }
   ],
   "source": [
    "people = sorted(list(set(dl2[\"displayname\"].tolist() ) ))\n",
    "print (len(people))\n",
    "dp2 = dp[dp['displayname'].isin(people)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0893562b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp2.to_csv(path + \"Exterminators from Person Dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "25f8041d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'NOBLDGACCESS',\n",
       " 'RESNOTHOME',\n",
       " 'RESREFUSED',\n",
       " 'UNFOUNDED',\n",
       " 'WORK',\n",
       " 'WORKWITHSEQ'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transtype = set(dl2[\"transtype\"].tolist() )\n",
    "transtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85028fcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unfounded 1607\n",
      "res refused 33828\n",
      "res not home 42537\n",
      "no bldg access 1220\n"
     ]
    }
   ],
   "source": [
    "a = dl2[dl2[\"transtype\"] == \"UNFOUNDED\"]\n",
    "print (\"unfounded\", len(a))\n",
    "\n",
    "a = dl2[dl2[\"transtype\"] == \"RESREFUSED\"]\n",
    "print (\"res refused\", len(a))\n",
    "\n",
    "a = dl2[dl2[\"transtype\"] == \"RESNOTHOME\"]\n",
    "print (\"res not home\", len(a))\n",
    "\n",
    "a = dl2[dl2[\"transtype\"] == \"NOBLDGACCESS\"]\n",
    "print (\"no bldg access\", len(a))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77f5bea7",
   "metadata": {},
   "source": [
    "### Get IPM Inspection Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7ca831",
   "metadata": {},
   "source": [
    "### With Labor Transactions Jan-Feb 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5ff2cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-14 16:42:42.553119\n",
      "Import questions and results\n"
     ]
    }
   ],
   "source": [
    "# wt = work orders table (workorder)\n",
    "# iq = inspection questions (zzinsquestion)\n",
    "# wr = work order results table (zzworesult)\n",
    "# lt = labor transactions (labtrans)\n",
    "\n",
    "\n",
    "\n",
    "import datetime\n",
    "print (str(datetime.datetime.today()) )\n",
    "\n",
    "print (\"Import questions and results\")\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "DIALECT = 'oracle'\n",
    "SQL_DRIVER = 'cx_oracle'\n",
    "USERNAME = '' #enter your username\n",
    "PASSWORD = '' #enter your password\n",
    "#HOST = 'exadm1-scan' #enter the oracle db host url\n",
    "HOST = '' #enter the oracle db host url\n",
    "\n",
    "PORT = 1521 # enter the oracle port number\n",
    "SERVICE = 'maxdb' # enter the oracle db service name\n",
    "ENGINE_PATH = DIALECT + '+' + SQL_DRIVER + '://' + USERNAME + ':' + PASSWORD +'@' + HOST + ':' + str(PORT) + '/?service_name=' + SERVICE\n",
    "\n",
    "engine = create_engine(ENGINE_PATH)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "ques_query = \"\"\"\n",
    "\n",
    "select wp.wonum wonum1, wp.description description1, wt.wonum wonum2, wt.description description2, \n",
    "iq.inslist, iq.questioncode, iq.description description3, wr.result, \n",
    "lt.laborcode,lt.ENTERDATE, lt.TRANSTYPE,lt.startdatetime,lt.finishdatetime\n",
    "\n",
    "from workorder wp, workorder wt, zzinsquestion iq, zzworesult wr, labtrans lt\n",
    "\n",
    "where  (wt.reportdate >= '01-JAN-2022' AND wt.reportdate <= '31-MAR-2022')\n",
    "\n",
    "and wt.status = 'CLOSE' and wt.failurecode = 'EXTERMINATION' \n",
    "and wt.worktype = 'CM' \n",
    "and wp.wonum = wt.parent and wt.istask = 1\n",
    "and wt.zzinslist = iq.inslist and nvl(wt.zzinslistrevnum, 0) = iq.revnum\n",
    "and wr.wonum = wt.wonum and wr.siteid = wt.siteid and wr.questioncode = iq.questioncode\n",
    "and lt.refwo = wp.wonum and lt.siteid = wp.siteid\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "#(wt.reportdate >= '01-JAN-2022' AND wt.reportdate <= '1-MAR-2022')\n",
    "#dq = pd.read_sql_query(ques_query, engine)\n",
    "\n",
    "#path = \"C:\\\\Users\\\\MehriD01\\\\Documents\\\\Pest\\\\\"\n",
    "#dq.to_csv(path + \"Labor_Transactions_jan-mar_2022.csv\", index=False)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf46155",
   "metadata": {},
   "source": [
    "### April - June 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5eb069b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-14 16:42:43.762249\n",
      "Import questions and results\n"
     ]
    }
   ],
   "source": [
    "# wt = work orders table (workorder)\n",
    "# iq = inspection questions (zzinsquestion)\n",
    "# wr = work order results table (zzworesult)\n",
    "# lt = labor transactions (labtrans)\n",
    "\n",
    "\n",
    "import datetime\n",
    "print (str(datetime.datetime.today()) )\n",
    "\n",
    "print (\"Import questions and results\")\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "DIALECT = 'oracle'\n",
    "SQL_DRIVER = 'cx_oracle'\n",
    "USERNAME = '' #enter your username\n",
    "PASSWORD = '' #enter your password\n",
    "#HOST = 'exadm1-scan' #enter the oracle db host url\n",
    "HOST = '' #enter the oracle db host url\n",
    "\n",
    "PORT = 1521 # enter the oracle port number\n",
    "SERVICE = 'maxdb' # enter the oracle db service name\n",
    "ENGINE_PATH = DIALECT + '+' + SQL_DRIVER + '://' + USERNAME + ':' + PASSWORD +'@' + HOST + ':' + str(PORT) + '/?service_name=' + SERVICE\n",
    "\n",
    "engine = create_engine(ENGINE_PATH)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "ques_query = \"\"\"\n",
    "\n",
    "select wp.wonum wonum1, wp.description description1, wt.wonum wonum2, wt.description description2, \n",
    "iq.inslist, iq.questioncode, iq.description description3, wr.result, \n",
    "lt.laborcode,lt.ENTERDATE, lt.TRANSTYPE,lt.startdatetime,lt.finishdatetime\n",
    "\n",
    "from workorder wp, workorder wt, zzinsquestion iq, zzworesult wr, labtrans lt\n",
    "\n",
    "where  (wt.reportdate >= '01-APR-2022' AND wt.reportdate <= '30-JUN-2022')\n",
    "\n",
    "and wt.status = 'CLOSE' and wt.failurecode = 'EXTERMINATION' \n",
    "and wt.worktype = 'CM' \n",
    "and wp.wonum = wt.parent and wt.istask = 1\n",
    "and wt.zzinslist = iq.inslist and nvl(wt.zzinslistrevnum, 0) = iq.revnum\n",
    "and wr.wonum = wt.wonum and wr.siteid = wt.siteid and wr.questioncode = iq.questioncode\n",
    "and lt.refwo = wp.wonum and lt.siteid = wp.siteid\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#(wt.reportdate >= '01-JAN-2022' AND wt.reportdate <= '1-MAR-2022')\n",
    "#dq = pd.read_sql_query(ques_query, engine)\n",
    "\n",
    "#path = \"C:\\\\Users\\\\MehriD01\\\\Documents\\\\Pest\\\\\"\n",
    "#dq.to_csv(path + \"Labor_Transactions_apr-jun_2022.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b254aef4",
   "metadata": {},
   "source": [
    "### July - Sept 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea5fa59d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-14 16:42:44.517580\n",
      "Import questions and results\n"
     ]
    }
   ],
   "source": [
    "# wt = work orders table (workorder)\n",
    "# iq = inspection questions (zzinsquestion)\n",
    "# wr = work order results table (zzworesult)\n",
    "# lt = labor transactions (labtrans)\n",
    "\n",
    "\n",
    "import datetime\n",
    "print (str(datetime.datetime.today()) )\n",
    "\n",
    "print (\"Import questions and results\")\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "DIALECT = 'oracle'\n",
    "SQL_DRIVER = 'cx_oracle'\n",
    "USERNAME = '' #enter your username\n",
    "PASSWORD = '' #enter your password\n",
    "#HOST = 'exadm1-scan' #enter the oracle db host url\n",
    "HOST = '' #enter the oracle db host url\n",
    "\n",
    "PORT = 1521 # enter the oracle port number\n",
    "SERVICE = 'maxdb' # enter the oracle db service name\n",
    "ENGINE_PATH = DIALECT + '+' + SQL_DRIVER + '://' + USERNAME + ':' + PASSWORD +'@' + HOST + ':' + str(PORT) + '/?service_name=' + SERVICE\n",
    "\n",
    "engine = create_engine(ENGINE_PATH)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "ques_query = \"\"\"\n",
    "\n",
    "select wp.wonum wonum1, wp.description description1, wt.wonum wonum2, wt.description description2, \n",
    "iq.inslist, iq.questioncode, iq.description description3, wr.result, \n",
    "lt.laborcode,lt.ENTERDATE, lt.TRANSTYPE,lt.startdatetime,lt.finishdatetime\n",
    "\n",
    "from workorder wp, workorder wt, zzinsquestion iq, zzworesult wr, labtrans lt\n",
    "\n",
    "where  (wt.reportdate >= '01-JUL-2022' AND wt.reportdate <= '30-SEP-2022')\n",
    "\n",
    "and wt.status = 'CLOSE' and wt.failurecode = 'EXTERMINATION' \n",
    "and wt.worktype = 'CM' \n",
    "and wp.wonum = wt.parent and wt.istask = 1\n",
    "and wt.zzinslist = iq.inslist and nvl(wt.zzinslistrevnum, 0) = iq.revnum\n",
    "and wr.wonum = wt.wonum and wr.siteid = wt.siteid and wr.questioncode = iq.questioncode\n",
    "and lt.refwo = wp.wonum and lt.siteid = wp.siteid\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#(wt.reportdate >= '01-JAN-2022' AND wt.reportdate <= '1-MAR-2022')\n",
    "#dq = pd.read_sql_query(ques_query, engine)\n",
    "\n",
    "#path = \"C:\\\\Users\\\\MehriD01\\\\Documents\\\\Pest\\\\\"\n",
    "#dq.to_csv(path + \"Labor_Transactions_jul-sept_2022.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f3351e6",
   "metadata": {},
   "source": [
    "### Oct - Dec 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c6dbe25e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-14 16:42:45.499057\n",
      "Import questions and results\n"
     ]
    }
   ],
   "source": [
    "# wt = work orders table (workorder)\n",
    "# iq = inspection questions (zzinsquestion)\n",
    "# wr = work order results table (zzworesult)\n",
    "# lt = labor transactions (labtrans)\n",
    "\n",
    "\n",
    "import datetime\n",
    "print (str(datetime.datetime.today()) )\n",
    "\n",
    "print (\"Import questions and results\")\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "DIALECT = 'oracle'\n",
    "SQL_DRIVER = 'cx_oracle'\n",
    "USERNAME = '' #enter your username\n",
    "PASSWORD = '' #enter your password\n",
    "#HOST = 'exadm1-scan' #enter the oracle db host url\n",
    "HOST = '' #enter the oracle db host url\n",
    "\n",
    "PORT = 1521 # enter the oracle port number\n",
    "SERVICE = 'maxdb' # enter the oracle db service name\n",
    "ENGINE_PATH = DIALECT + '+' + SQL_DRIVER + '://' + USERNAME + ':' + PASSWORD +'@' + HOST + ':' + str(PORT) + '/?service_name=' + SERVICE\n",
    "\n",
    "engine = create_engine(ENGINE_PATH)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "ques_query = \"\"\"\n",
    "\n",
    "select wp.wonum wonum1, wp.description description1, wt.wonum wonum2, wt.description description2, \n",
    "iq.inslist, iq.questioncode, iq.description description3, wr.result, \n",
    "lt.laborcode,lt.ENTERDATE, lt.TRANSTYPE,lt.startdatetime,lt.finishdatetime\n",
    "\n",
    "from workorder wp, workorder wt, zzinsquestion iq, zzworesult wr, labtrans lt\n",
    "\n",
    "where  (wt.reportdate >= '01-OCT-2022' AND wt.reportdate <= '31-DEC-2022')\n",
    "\n",
    "and wt.status = 'CLOSE' and wt.failurecode = 'EXTERMINATION' \n",
    "and wt.worktype = 'CM' \n",
    "and wp.wonum = wt.parent and wt.istask = 1\n",
    "and wt.zzinslist = iq.inslist and nvl(wt.zzinslistrevnum, 0) = iq.revnum\n",
    "and wr.wonum = wt.wonum and wr.siteid = wt.siteid and wr.questioncode = iq.questioncode\n",
    "and lt.refwo = wp.wonum and lt.siteid = wp.siteid\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#(wt.reportdate >= '01-JAN-2022' AND wt.reportdate <= '1-MAR-2022')\n",
    "#dq = pd.read_sql_query(ques_query, engine)\n",
    "\n",
    "#path = \"C:\\\\Users\\\\MehriD01\\\\Documents\\\\Pest\\\\\"\n",
    "#dq.to_csv(path + \"Labor_Transactions_oct-dec_2022.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72865efc",
   "metadata": {},
   "source": [
    "### Jan 2023 - Present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b8f7a357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-12 12:35:25.564953\n",
      "Import questions and results\n",
      "3253521\n"
     ]
    }
   ],
   "source": [
    "# wt = work orders table (workorder)\n",
    "# iq = inspection questions (zzinsquestion)\n",
    "# wr = work order results table (zzworesult)\n",
    "# lt = labor transactions (labtrans)\n",
    "\n",
    "\n",
    "import datetime\n",
    "print (str(datetime.datetime.today()) )\n",
    "\n",
    "print (\"Import questions and results\")\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "DIALECT = 'oracle'\n",
    "SQL_DRIVER = 'cx_oracle'\n",
    "USERNAME = '' #enter your username\n",
    "PASSWORD = '' #enter your password\n",
    "#HOST = 'exadm1-scan' #enter the oracle db host url\n",
    "HOST = '' #enter the oracle db host url\n",
    "\n",
    "PORT = 1521 # enter the oracle port number\n",
    "SERVICE = 'maxdb' # enter the oracle db service name\n",
    "ENGINE_PATH = DIALECT + '+' + SQL_DRIVER + '://' + USERNAME + ':' + PASSWORD +'@' + HOST + ':' + str(PORT) + '/?service_name=' + SERVICE\n",
    "\n",
    "engine = create_engine(ENGINE_PATH)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "ques_query = \"\"\"\n",
    "\n",
    "select wp.wonum wonum1, wp.description description1, wt.wonum wonum2, wt.description description2, \n",
    "iq.inslist, iq.questioncode, iq.description description3, wr.result, \n",
    "lt.laborcode,lt.ENTERDATE, lt.TRANSTYPE,lt.startdatetime,lt.finishdatetime\n",
    "\n",
    "from workorder wp, workorder wt, zzinsquestion iq, zzworesult wr, labtrans lt\n",
    "\n",
    "where  wt.reportdate >= '31-MAR-2023'\n",
    "\n",
    "\n",
    "and wt.status = 'CLOSE' and wt.failurecode = 'EXTERMINATION' \n",
    "and wt.worktype = 'CM' \n",
    "and wp.wonum = wt.parent and wt.istask = 1\n",
    "and wt.zzinslist = iq.inslist and nvl(wt.zzinslistrevnum, 0) = iq.revnum\n",
    "and wr.wonum = wt.wonum and wr.siteid = wt.siteid and wr.questioncode = iq.questioncode\n",
    "and lt.refwo = wp.wonum and lt.siteid = wp.siteid\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#(wt.reportdate >= '01-JAN-2022' AND wt.reportdate <= '1-MAR-2022')\n",
    "dq = pd.read_sql_query(ques_query, engine)\n",
    "\n",
    "print (len(dq))\n",
    "\n",
    "path = \"C:\\\\Users\\\\MehriD01\\\\Documents\\\\Pest\\\\\"\n",
    "dq.to_csv(path + \"Labor_Transactions_mar_2023-present.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fef697c",
   "metadata": {},
   "source": [
    "### Concatinate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "012796a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-12 12:59:29.320511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MehriD01\\AppData\\Local\\Temp\\ipykernel_6536\\2401751053.py:6: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  dq4 = pd.read_csv(path + \"Labor_Transactions_oct-dec_2022.csv\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1172278, 13)\n",
      "(9538360, 13)\n",
      "9538360\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "print (str(datetime.datetime.today()) )\n",
    "\n",
    "#dq1 = pd.read_csv(path + \"Labor_Transactions_jan-mar_2022.csv\")\n",
    "#dq2 = pd.read_csv(path + \"Labor_Transactions_apr-jun_2022.csv\")\n",
    "#dq3 = pd.read_csv(path + \"Labor_Transactions_jul-sept_2022.csv\")\n",
    "#dq4 = pd.read_csv(path + \"Labor_Transactions_oct-dec_2022.csv\")\n",
    "#dq5 = pd.read_csv(path + \"Labor_Transactions_jan-mar_2023.csv\")\n",
    "#dq6 = pd.read_csv(path + \"Labor_Transactions_mar_2023-present.csv\")\n",
    "\n",
    "#print (dq1.shape)\n",
    "\n",
    "#frames = [dq1, dq2, dq3, dq4, dq5, dq6]\n",
    "\n",
    "dq2 = dq.copy()\n",
    "dq1 = pd.read_csv(path + \"Labor_Transactions_ALL_jan_22-present.csv\")\n",
    "frames = [dq1, dq2]\n",
    "\n",
    "\n",
    "dq = pd.concat(frames)\n",
    "dq = dq.reset_index(drop=True)\n",
    "\n",
    "print (dq.shape)\n",
    "\n",
    "print (len(dq))\n",
    "\n",
    "dq = dq[[\"wonum1\", \"description3\", \"result\"]]\n",
    "\n",
    "print (\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "64ae4364",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dq.to_csv(path + \"Labor_Transactions_ALL_jan_22-present.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0235359a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dq.to_csv(path + \"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d8a23b2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "347414\n",
      "265901\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dq[\"wonum1\"] = dq[\"wonum1\"].astype(str).map(str.strip)\n",
    "dl2['refwo'] = dl2['refwo'].astype(str).map(str.strip)\n",
    "\n",
    "wolist = list(set(dq[\"wonum1\"].tolist()  ))\n",
    "\n",
    "print (len(dl2))\n",
    "dl3 = dl2[dl2['refwo'].isin(wolist)].reset_index(drop=True)\n",
    "print (len(dl3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1f441d",
   "metadata": {},
   "source": [
    "### Insert Qustions and Results into Labor Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b01a0f95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Was Resident Educational Literature issued\n",
      "130670\n",
      "Frass Removal\n",
      "217833\n",
      "HEPA Vacuum\n",
      "217833\n",
      "Fill holes with excluder mesh or similar product\n",
      "273396\n",
      "Sealing\n",
      "273396\n",
      "Escutcheon Plate Installation\n",
      "210824\n"
     ]
    }
   ],
   "source": [
    "#desc = sorted(list(set(dq[\"description3\"].tolist() ) ))\n",
    "#desc.remove('Adjacent Apartment 1')\n",
    "#desc.remove('Adjacent Apartment 2')\n",
    "#desc.remove('Adjacent Apartment 3')\n",
    "#desc.remove('Adjacent Apartment 4')\n",
    "\n",
    "\n",
    "desc = [\"Was Resident Educational Literature issued\",\"Frass Removal\", \"HEPA Vacuum\", \n",
    "       \"Fill holes with excluder mesh or similar product\",\"Sealing\", \"Escutcheon Plate Installation\" ]\n",
    "\n",
    "dq2 = dq.copy()\n",
    "\n",
    "dq2[\"wonum1\"] = dq2[\"wonum1\"].astype(str).map(str.strip)\n",
    "dl3['refwo'] = dl3['refwo'].astype(str).map(str.strip)\n",
    "\n",
    "\n",
    "for d in desc:\n",
    "    #print (d)\n",
    "    dq3 = dq2[dq2[\"description3\"] == d]\n",
    "    print (d)\n",
    "    print (len(dq3) )\n",
    "    #print (dq3)\n",
    "    \n",
    "    dq3Dic = dq3.set_index('wonum1')['result'].to_dict()\n",
    "\n",
    "    dl3[d] = dl3[\"refwo\"].map(dq3Dic)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7b23c1",
   "metadata": {},
   "source": [
    "### Calculate Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d1b3efc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-12 13:56:45.412471\n",
      "Calculate time\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "print (str(datetime.datetime.today()) )\n",
    "print (\"Calculate time\")\n",
    "\n",
    "dl3['startdatetime'] = pd.to_datetime(dl3['startdatetime'])\n",
    "\n",
    "dl3['finishdatetime'] = pd.to_datetime(dl3['finishdatetime'])\n",
    "\n",
    "\n",
    "#df2['Hours'] = (df2[\"actfinish\"] - df2[\"actstart\"]).dt.days\n",
    "\n",
    "pd.set_option('chained_assignment', None)\n",
    "\n",
    "dl3 = dl3.reset_index(drop=True)\n",
    "\n",
    "dl3['Seconds'] = (dl3[\"finishdatetime\"] - dl3[\"startdatetime\"]).dt.seconds\n",
    "dl3['Hours'] = (dl3[\"finishdatetime\"] - dl3[\"startdatetime\"]).dt.seconds / 3600.0\n",
    "dl3['Minutes'] = (dl3[\"finishdatetime\"] - dl3[\"startdatetime\"]).dt.seconds / 60.0\n",
    "dl3['Days'] = (dl3[\"finishdatetime\"] - dl3[\"startdatetime\"]).dt.days\n",
    "\n",
    "dl3[\"Hours\"] = dl3[\"Hours\"].astype(float)\n",
    "dl3[\"Hours\"] = dl3[\"Hours\"].round(2)\n",
    "\n",
    "dl3[\"Minutes\"] = dl3[\"Minutes\"].astype(float)\n",
    "dl3[\"Minutes\"] = dl3[\"Minutes\"].round(2)\n",
    "print (\"DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424cfeb1",
   "metadata": {},
   "source": [
    "### Merge Building and Development Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5fb785d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-12 13:56:53.254966\n",
      "Import nycha_org_dim\n",
      "2023-10-12\n",
      "398\n",
      "398\n",
      "Merge with labor transactions\n",
      "265901\n",
      "265901\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "print (str(datetime.datetime.today()) )\n",
    "\n",
    "dl3['location'] = dl3['location'].astype(str)\n",
    "\n",
    "dl3[\"TDS\"] = dl3['location'].str.split(\".\").str[0]\n",
    "\n",
    "print (\"Import nycha_org_dim\")\n",
    "\n",
    "import time\n",
    "start = time.time()\n",
    "\n",
    "import datetime\n",
    "print (str(datetime.datetime.today()).split()[0] )\n",
    "\n",
    "#from datetime import datetime\n",
    "#print (start )\n",
    "\n",
    "DIALECT = 'oracle'\n",
    "SQL_DRIVER = 'cx_oracle'\n",
    "USERNAME = '' #enter your username\n",
    "PASSWORD = '' #enter your password\n",
    "#HOST = 'exadm1-scan' #enter the oracle db host url\n",
    "HOST = '' #enter the oracle db host url\n",
    "\n",
    "PORT = 1521 # enter the oracle port number\n",
    "SERVICE = 'maxdb' # enter the oracle db service name\n",
    "ENGINE_PATH = DIALECT + '+' + SQL_DRIVER + '://' + USERNAME + ':' + PASSWORD +'@' + HOST + ':' + str(PORT) + '/?service_name=' + SERVICE\n",
    "\n",
    "engine = create_engine(ENGINE_PATH)\n",
    "\n",
    "\n",
    "nycha_org_query = \"\"\"\n",
    "\n",
    "select *\n",
    "       \n",
    "from maximo.nycha_org_dim nychaorg\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "dnycha = pd.read_sql_query(nycha_org_query, engine)\n",
    "\n",
    "subset = ['tds_num', 'borough_name', 'development_name']\n",
    "\n",
    "dnycha= dnycha[subset]\n",
    "\n",
    "\n",
    "tds = dnycha.tds_num.tolist()\n",
    "\n",
    "tdslist = []\n",
    "\n",
    "for c in tds:\n",
    "    c = str(c)\n",
    "    \n",
    "    #print (c)\n",
    "    \n",
    "    if len(c) == 1:\n",
    "        c = \"00\" + c\n",
    "        tdslist.append(c)\n",
    "    elif len(c) == 2:\n",
    "        c = \"0\" + c\n",
    "        tdslist.append(c)\n",
    "    else:\n",
    "        tdslist.append(c)\n",
    "\n",
    "\n",
    "print (len(tdslist))\n",
    "print (len(dnycha))\n",
    "\n",
    "qn = pd.DataFrame(tdslist)\n",
    "\n",
    "qn = qn.rename(columns={0: 'TDS'})\n",
    "\n",
    "dnycha = pd.concat([dnycha, qn], axis=1)\n",
    "\n",
    "print (\"Merge with labor transactions\")\n",
    "print (len(dl3))\n",
    "dl3 = pd.merge(dl3, dnycha, how='left', on=['TDS'])\n",
    "print (len(dl3))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631fbfda",
   "metadata": {},
   "source": [
    "### Insert Address"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0d37d633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-12\n",
      "{'BK', 'QS', 'MN', 'BX'}\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "print (str(datetime.datetime.today()).split()[0] )\n",
    "\n",
    "path2 = \"C:\\\\Users\\\\MehriD01\\\\Documents\\\\Data\\\\\"\n",
    "\n",
    "db = pd.read_csv(path2 + \"zzbuildings.csv\", low_memory=False)\n",
    "\n",
    "db[\"BUILDING\"] = db[\"BUILDING\"].astype(str)\n",
    "db[\"BLDGNO\"] = db[\"BLDGNO\"].astype(str)\n",
    "\n",
    "db[\"TDS\"] = db[\"BUILDING\"].str.split(\".\").str[0]\n",
    "\n",
    "#convert 1 to 01\n",
    "for i in range(0, len(db)):\n",
    "    a = db[\"BLDGNO\"][i]\n",
    "    if len(a) == 1:\n",
    "        db[\"BLDGNO\"][i] = \"0\" + db[\"BLDGNO\"][i]\n",
    "        \n",
    "    b = db[\"TDS\"][i]\n",
    "    if len(b) == 1:\n",
    "        db[\"TDS\"][i] = \"00\" + db[\"TDS\"][i]\n",
    "    if len(b) == 2:\n",
    "        db[\"TDS\"][i] = \"0\" + db[\"TDS\"][i] \n",
    "        \n",
    "\n",
    "\n",
    "db[\"Building\"] = db[\"TDS\"] + \".\" + db[\"BLDGNO\"]\n",
    "\n",
    "\n",
    "\n",
    "sitid = set(db[\"SITEID\"].tolist() )\n",
    "print(sitid)\n",
    "\n",
    "db[\"SITEID\"] = db[\"SITEID\"].str.replace('BK', 'BROOKYN')\n",
    "db[\"SITEID\"] = db[\"SITEID\"].str.replace('BX', 'BRONX')\n",
    "db[\"SITEID\"] = db[\"SITEID\"].str.replace('QS', 'QUEENS/STATEN ISLAND')\n",
    "db[\"SITEID\"] = db[\"SITEID\"].str.replace('MN', 'MANHATTAN')\n",
    "\n",
    "db[\"ADDRESS\"] = db[\"ADDRESS\"] + \", \" + db[\"SITEID\"]\n",
    "\n",
    "\n",
    "dl3[\"Building No\"] = dl3['location'].str.split(\".\").str[1]\n",
    "\n",
    "dl3[\"TDS\"] = dl3[\"TDS\"].astype(str)\n",
    "dl3[\"Building\"] = dl3[\"TDS\"] + \".\" + dl3[\"Building No\"]\n",
    "\n",
    "\n",
    "#dictionary to insert data\n",
    "dbDic = db.set_index('Building')['ADDRESS'].to_dict()\n",
    "\n",
    "dl3[\"Building Address\"] = dl3[\"Building\"].map(dbDic)\n",
    "\n",
    "dl3[\"Building Address\"] = dl3[\"Building Address\"].astype(str).map(str.strip)\n",
    "\n",
    "print (\"DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b4d635",
   "metadata": {},
   "source": [
    "### Insert Lat/Lon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a45d6692",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-12\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "print (str(datetime.datetime.today()).split()[0] )\n",
    "\n",
    "path2 = \"C:\\\\Users\\\\MehriD01\\\\Documents\\\\Data\\\\\"\n",
    "\n",
    "dgis = pd.read_csv(path2 + \"nycha_loc_gps.csv\", low_memory=False)\n",
    "\n",
    "dgis[\"TDS_NUM\"] = dgis[\"TDS_NUM\"].astype(str)\n",
    "dgis[\"BLDG_NUM\"] = dgis[\"BLDG_NUM\"].astype(str)\n",
    "\n",
    "for i in range(0, len(dgis)):\n",
    "    a = dgis[\"BLDG_NUM\"][i]\n",
    "    if len(a) == 1:\n",
    "        dgis[\"BLDG_NUM\"][i] = \"0\" + dgis[\"BLDG_NUM\"][i]\n",
    "        \n",
    "    b = dgis[\"TDS_NUM\"][i]\n",
    "    if len(b) == 1:\n",
    "        dgis[\"TDS_NUM\"][i] = \"00\" + dgis[\"TDS_NUM\"][i]\n",
    "    if len(b) == 2:\n",
    "        dgis[\"TDS_NUM\"][i] = \"0\" + dgis[\"TDS_NUM\"][i]            \n",
    "\n",
    "dgis[\"Building\"] = dgis[\"TDS_NUM\"] + \".\" + dgis[\"BLDG_NUM\"]\n",
    "\n",
    "lat = dgis.set_index('Building')['LATITUDE'].to_dict()\n",
    "dl3[\"lat\"] = dl3[\"Building\"].map(lat)\n",
    "\n",
    "lon = dgis.set_index('Building')['LONGITUDE'].to_dict()\n",
    "dl3[\"lon\"] = dl3[\"Building\"].map(lon)\n",
    "\n",
    "print (\"DONE\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "044c8832",
   "metadata": {},
   "source": [
    "### Flag Work orders < 10 Minutes > 120 Minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7546fb51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-12\n",
      "265901\n",
      "265901\n",
      "265901\n",
      "265901\n",
      "265901\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "print (str(datetime.datetime.today()).split()[0] )\n",
    "\n",
    "minutes = dl3[\"Minutes\"].tolist()\n",
    "minutes\n",
    "\n",
    "mintues30flag = []\n",
    "mintues10flag = []\n",
    "mintues120flag = []\n",
    "greater10minutesflag = []\n",
    "\n",
    "\n",
    "for i in range(0, len(minutes)):\n",
    "    if minutes[i] < 30:\n",
    "        mintues30flag.append(1)\n",
    "    else:\n",
    "        mintues30flag.append(0)\n",
    "        \n",
    "        \n",
    "    if minutes[i] < 10:\n",
    "        mintues10flag.append(1)\n",
    "    else:\n",
    "        mintues10flag.append(0)\n",
    "        \n",
    "        \n",
    "    if minutes[i] > 120:\n",
    "        mintues120flag.append(1)\n",
    "    else:\n",
    "        mintues120flag.append(0)\n",
    "        \n",
    "    if minutes[i] > 10:\n",
    "        greater10minutesflag.append(\"Yes\")\n",
    "    else:\n",
    "        greater10minutesflag.append(\"No\")\n",
    "        \n",
    "        \n",
    "        \n",
    "print (len(mintues30flag))\n",
    "print (len(mintues10flag))\n",
    "print (len(mintues120flag))\n",
    "print (len(greater10minutesflag))\n",
    "print (len(dl3))\n",
    "\n",
    "dl3[\"<30 min\"] = mintues30flag\n",
    "dl3[\"<10 min\"] = mintues10flag\n",
    "dl3[\">120 min\"] = mintues120flag\n",
    "dl3[\">10 min\"] = greater10minutesflag\n",
    "\n",
    "print (\"DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12678471",
   "metadata": {},
   "source": [
    "### Create Apartment String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3184da39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-12\n",
      "265901\n",
      "265901\n"
     ]
    }
   ],
   "source": [
    "dl3 = dl3.reset_index(drop=True)\n",
    "\n",
    "#line = \"071.04.008.F01.01A.KIT01\"\n",
    "#updated_line = '.'.join(line.split('.')[:-1])\n",
    "print (str(datetime.datetime.today()).split()[0] )\n",
    "\n",
    "\n",
    "updated_line = []\n",
    "\n",
    "for i in range(0, len(dl3)):\n",
    "    line = dl3[\"location\"][i]\n",
    "    linesplit = line.split(\".\")\n",
    "    \n",
    "    if len(linesplit) == 6:\n",
    "        a = '.'.join(line.split('.')[:-1])\n",
    "        #print (a)\n",
    "        updated_line.append(a)\n",
    "    else:\n",
    "        #print (line)\n",
    "        updated_line.append(line)\n",
    "\n",
    "print (len(dl3))\n",
    "print (len(updated_line))\n",
    "\n",
    "dl3[\"Apartment\"] = updated_line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16378d7f",
   "metadata": {},
   "source": [
    "### Calculate occurence of questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fb04dc84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-12\n",
      "265901\n",
      "265901\n",
      "265901\n",
      "265901\n"
     ]
    }
   ],
   "source": [
    "#dl3[\"Percent No\"] = \"\"\n",
    "print (str(datetime.datetime.today()).split()[0] )\n",
    "\n",
    "dl3[\"Was Resident Educational Literature issued\"] = dl3[\"Was Resident Educational Literature issued\"].astype(str)\n",
    "dl3[\"Frass Removal\"] = dl3[\"Frass Removal\"].astype(str)\n",
    "dl3[\"HEPA Vacuum\"] = dl3[\"HEPA Vacuum\"].astype(str)\n",
    "dl3[\"Fill holes with excluder mesh or similar product\"] = dl3[\"Fill holes with excluder mesh or similar product\"].astype(str)\n",
    "dl3[\"Sealing\"] = dl3[\"Sealing\"].astype(str)\n",
    "dl3[\"Escutcheon Plate Installation\"] = dl3[\"Escutcheon Plate Installation\"].astype(str)\n",
    "\n",
    "\n",
    "percent_no = []\n",
    "percent_yes = []\n",
    "percent_nan = []\n",
    "\n",
    "for i in range(0, len(dl3)):\n",
    "    count = []\n",
    "    d = dl3[\"Was Resident Educational Literature issued\"][i]\n",
    "    count.append(d)\n",
    "    \n",
    "    d = dl3[\"Frass Removal\"][i]\n",
    "    count.append(d)\n",
    "    \n",
    "    d = dl3[\"HEPA Vacuum\"][i]\n",
    "    count.append(d)\n",
    "    \n",
    "    d = dl3[\"Fill holes with excluder mesh or similar product\"][i]\n",
    "    count.append(d)\n",
    "    \n",
    "    d = dl3[\"Sealing\"][i]\n",
    "    count.append(d)\n",
    "    \n",
    "    d = dl3[\"Escutcheon Plate Installation\"][i]\n",
    "    count.append(d)\n",
    "    \n",
    "    n = (count.count('N')/6)\n",
    "    n = round(n, 2)\n",
    "    y = (count.count('Y')/6)\n",
    "    y = round(y, 2)\n",
    "    nan = (count.count('nan')/6)\n",
    "    nan = round(nan, 2)\n",
    "\n",
    "    percent_no.append(n)\n",
    "    percent_yes.append(y)\n",
    "    percent_nan.append(nan)\n",
    "\n",
    "    \n",
    "\n",
    "print (len(dl3))   \n",
    "print (len(percent_no))   \n",
    "print (len(percent_yes))   \n",
    "print (len(percent_nan))   \n",
    "\n",
    " \n",
    "dl3[\"Percent No\"] = percent_no\n",
    "dl3[\"Percent Yes\"] = percent_yes\n",
    "dl3[\"Percent nan\"] = percent_nan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd613954",
   "metadata": {},
   "source": [
    "### Convert Transaction Type to Dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3f19dd9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-12\n",
      "Convert transactions to dummies\n",
      "265901\n",
      "265901\n",
      "265901\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "print (str(datetime.datetime.today()).split()[0] )\n",
    "\n",
    "print (\"Convert transactions to dummies\")\n",
    "transaction_dummies = pd.get_dummies(dl3[\"transtype\"])\n",
    "\n",
    "transaction_dummies[\"WORK\"] = transaction_dummies[\"WORK\"] + transaction_dummies[\"WORKWITHSEQ\"]\n",
    "\n",
    "subset =  ['NOBLDGACCESS', 'RESNOTHOME', 'RESREFUSED', 'UNFOUNDED', 'WORK']\n",
    "transaction_dummies = transaction_dummies[subset]\n",
    "\n",
    "transaction_dummies.to_csv ( path + \"test.csv\", index=False)\n",
    "\n",
    "print (len(transaction_dummies))\n",
    "print (len(dl3))\n",
    "\n",
    "dl4 = pd.concat([dl3, transaction_dummies], axis=1)\n",
    "\n",
    "print (len(dl4))\n",
    "\n",
    "print (\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6aceaa1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['NOBLDGACCESS', 'RESNOTHOME', 'RESREFUSED', 'UNFOUNDED', 'WORK'], dtype='object')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = transaction_dummies.columns\n",
    "cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "963da6a4",
   "metadata": {},
   "source": [
    "### Remove Non-NYCHA Employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6995b0e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-12\n",
      "remove non nycha employees\n",
      "len before drop 265901\n",
      "len after drop 195072\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "print (str(datetime.datetime.today()).split()[0] )\n",
    "\n",
    "\n",
    "print (\"remove non nycha employees\")\n",
    "\n",
    "dn = pd.read_csv(path + \"7A Exterminators Group_Validation_Records as of 03-30-2023.csv\")\n",
    "\n",
    "dn[\"Badge #\"] = dn[\"Badge #\"].astype(str).map(str.strip)\n",
    "\n",
    "badge = dn[\"Badge #\"].tolist()\n",
    "\n",
    "\n",
    "for i in range(len(badge)):\n",
    "    #print (len(badge[i]))\n",
    "    \n",
    "    if len(badge[i]) == 2:\n",
    "        badge[i] = \"0000\" + badge[i]\n",
    "        \n",
    "    if len(badge[i]) == 3:\n",
    "        badge[i] = \"000\" + badge[i]\n",
    "        \n",
    "    if len(badge[i]) == 4:\n",
    "        badge[i] = \"00\" + badge[i]\n",
    "        \n",
    "    if len(badge[i]) == 5:\n",
    "        badge[i] = \"0\" + badge[i]\n",
    "        \n",
    "dn[\"Badge #\"] = badge\n",
    "\n",
    "dn[\"Employee Type\"] = \"NYCHA Employee\"\n",
    "\n",
    "dnDic = dn.set_index('Badge #')['Employee Type'].to_dict()\n",
    "\n",
    "\n",
    "dl4[\"laborcode\"] = dl4[\"laborcode\"].astype(str).map(str.strip)\n",
    "\n",
    "dl4[\"Employee Type\"] = dl4[\"laborcode\"].map(dnDic)\n",
    "\n",
    "dl4[\"Employee Type\"] = dl4[\"Employee Type\"].fillna(\"Other\")\n",
    "\n",
    "print (\"len before drop\", len(dl4))\n",
    "\n",
    "dl4 = dl4[dl4[\"Employee Type\"] == \"NYCHA Employee\"]\n",
    "\n",
    "print (\"len after drop\", len(dl4))\n",
    "\n",
    "print (\"DONE\")\n",
    "\n",
    "\n",
    "dl4 = dl4.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acfecb35",
   "metadata": {},
   "source": [
    "### Change Field Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b3e8ed38",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl4[\"Finish Date\"] = dl4[\"finishdatetime\"].apply(lambda x: x.date())\n",
    "dl4[\"Start Date\"] = dl4[\"startdatetime\"].apply(lambda x: x.date())\n",
    "dl4 = dl4.rename(columns={'problemcode': 'Problem Code'})\n",
    "dl4 = dl4.rename(columns={'failurecode': 'Failure Code'})\n",
    "dl4 = dl4.rename(columns={'ownergroup': 'Owner Group'})\n",
    "dl4 = dl4.rename(columns={'transtype': 'Transaction Type'})\n",
    "dl4 = dl4.rename(columns={'status': 'Status'})\n",
    "dl4 = dl4.rename(columns={'displayname': 'Name'})\n",
    "dl4 = dl4.rename(columns={'department': 'Department'})\n",
    "dl4 = dl4.rename(columns={'title': 'Title'})\n",
    "dl4 = dl4.rename(columns={'zzhrtitle': 'HR Title'})\n",
    "dl4 = dl4.rename(columns={'zzcraft': 'Craft'})\n",
    "dl4 = dl4.rename(columns={'Enterdate': 'Enter Date'})\n",
    "\n",
    "\n",
    "dl4[\"Count\"] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b38cd24",
   "metadata": {},
   "source": [
    "### Calculate Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f7de57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transtype = list(set(dl4[\"Transaction Type\"].tolist() ) )\n",
    "#transtype\n",
    "#transtype = list(set(dl4[\"Transaction Type 2\"].tolist() ) )\n",
    "#transtype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "22aff77a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-12\n",
      "WORK\n",
      "NO ACCESS\n",
      "UNFOUNDED\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "print (str(datetime.datetime.today()).split()[0] )\n",
    "\n",
    "#dl5 = dl4[\"Name\", \"Transaction Type\", \"Minutes\"]\n",
    "\n",
    "\n",
    "\n",
    "dl4[\"Transaction Type 2\"] = dl4[\"Transaction Type\"]\n",
    "dl4[\"Transaction Type 2\"] = dl4[\"Transaction Type 2\"].str.replace('WORKWITHSEQ', 'WORK')\n",
    "dl4[\"Transaction Type 2\"] = dl4[\"Transaction Type 2\"].str.replace('NOBLDGACCESS', 'NO ACCESS')\n",
    "dl4[\"Transaction Type 2\"] = dl4[\"Transaction Type 2\"].str.replace('RESNOTHOME', 'NO ACCESS')\n",
    "dl4[\"Transaction Type 2\"] = dl4[\"Transaction Type 2\"].str.replace('RESREFUSED', 'NO ACCESS')\n",
    "\n",
    "transtype = list(set(dl4[\"Transaction Type 2\"].tolist() ) )\n",
    "\n",
    "\n",
    "print (\"WORK\")\n",
    "\n",
    "qn = pd.DataFrame(columns=('Emplpoyee Name', 'Mode', 'Count of Mode', 'Total Number of Labor Transactions', \n",
    "                           'Transaction Type'))\n",
    "\n",
    "names = sorted(list(set(dl4[\"Name\"].tolist()  )))\n",
    "\n",
    "dl4[\"Minutes\"] = dl4[\"Minutes\"].astype(int)\n",
    "dl4[\"MinutesCat\"] = dl4[\"Minutes\"].astype(str)\n",
    "\n",
    "for i in range(0, len(names)):\n",
    "    n = names[i]\n",
    "    \n",
    "  \n",
    "    dl5 = dl4[dl4[\"Name\"] == n].reset_index(drop=True)\n",
    "    dl5 = dl5[dl5[\"Transaction Type 2\"] == \"WORK\"].reset_index(drop=True)\n",
    "\n",
    "    #dfb2 = dfb2[dfb2[\"AptWatTemp\"] != \"nan_nan\"].reset_index(drop=True)\n",
    "\n",
    "    dl5[\"Count\"] = 1\n",
    "\n",
    "    dl5G = dl5[[\"MinutesCat\", \"Count\"]]\n",
    "\n",
    "    dl5G = dl5G.groupby(['MinutesCat']).sum()\n",
    "    dl5G = dl5G.add_suffix('').reset_index()\n",
    "    dl5G = dl5G.sort_values(by = 'Count', ascending=False).reset_index(drop=True)\n",
    "        \n",
    "    if len(dl5G) > 0:\n",
    "        qn.loc[i] = [n,dl5G[\"MinutesCat\"][0],dl5G[\"Count\"][0], len(dl5), \"WORK\" ]\n",
    "\n",
    "qn[\"Mode Relative Frequency\"] = qn[\"Count of Mode\"]/qn[\"Total Number of Labor Transactions\"]\n",
    "qn[\"Mode Relative Frequency\"] = qn[\"Mode Relative Frequency\"].astype(float)\n",
    "qn[\"Mode Relative Frequency\"] = qn[\"Mode Relative Frequency\"].round(2)\n",
    "\n",
    "qn1 = qn.copy()\n",
    "\n",
    "\n",
    "\n",
    "print (\"NO ACCESS\")\n",
    "\n",
    "qn = pd.DataFrame(columns=('Emplpoyee Name', 'Mode', 'Count of Mode', 'Total Number of Labor Transactions', \n",
    "                           'Transaction Type'))\n",
    "\n",
    "names = sorted(list(set(dl4[\"Name\"].tolist()  )))\n",
    "\n",
    "dl4[\"Minutes\"] = dl4[\"Minutes\"].astype(int)\n",
    "dl4[\"MinutesCat\"] = dl4[\"Minutes\"].astype(str)\n",
    "\n",
    "for i in range(0, len(names)):\n",
    "    n = names[i]\n",
    "    \n",
    "  \n",
    "    dl5 = dl4[dl4[\"Name\"] == n].reset_index(drop=True)\n",
    "    dl5 = dl5[dl5[\"Transaction Type 2\"] == \"NO ACCESS\"].reset_index(drop=True)\n",
    "\n",
    "    #dfb2 = dfb2[dfb2[\"AptWatTemp\"] != \"nan_nan\"].reset_index(drop=True)\n",
    "\n",
    "    dl5[\"Count\"] = 1\n",
    "\n",
    "    dl5G = dl5[[\"MinutesCat\", \"Count\"]]\n",
    "\n",
    "    dl5G = dl5G.groupby(['MinutesCat']).sum()\n",
    "    dl5G = dl5G.add_suffix('').reset_index()\n",
    "    dl5G = dl5G.sort_values(by = 'Count', ascending=False).reset_index(drop=True)\n",
    "        \n",
    "    if len(dl5G) > 0:\n",
    "        qn.loc[i] = [n,dl5G[\"MinutesCat\"][0],dl5G[\"Count\"][0], len(dl5), \"NO ACCESS\" ]\n",
    "\n",
    "qn[\"Mode Relative Frequency\"] = qn[\"Count of Mode\"]/qn[\"Total Number of Labor Transactions\"]\n",
    "qn[\"Mode Relative Frequency\"] = qn[\"Mode Relative Frequency\"].astype(float)\n",
    "qn[\"Mode Relative Frequency\"] = qn[\"Mode Relative Frequency\"].round(2)\n",
    "\n",
    "qn2 = qn.copy()\n",
    "\n",
    "\n",
    "\n",
    "print (\"UNFOUNDED\")\n",
    "\n",
    "qn = pd.DataFrame(columns=('Emplpoyee Name', 'Mode', 'Count of Mode', 'Total Number of Labor Transactions', \n",
    "                           'Transaction Type'))\n",
    "\n",
    "names = sorted(list(set(dl4[\"Name\"].tolist()  )))\n",
    "\n",
    "dl4[\"Minutes\"] = dl4[\"Minutes\"].astype(int)\n",
    "dl4[\"MinutesCat\"] = dl4[\"Minutes\"].astype(str)\n",
    "\n",
    "for i in range(0, len(names)):\n",
    "    n = names[i]\n",
    "    \n",
    "  \n",
    "    dl5 = dl4[dl4[\"Name\"] == n].reset_index(drop=True)\n",
    "    dl5 = dl5[dl5[\"Transaction Type 2\"] == \"NO ACCESS\"].reset_index(drop=True)\n",
    "\n",
    "    #dfb2 = dfb2[dfb2[\"AptWatTemp\"] != \"nan_nan\"].reset_index(drop=True)\n",
    "\n",
    "    dl5[\"Count\"] = 1\n",
    "\n",
    "    dl5G = dl5[[\"MinutesCat\", \"Count\"]]\n",
    "\n",
    "    dl5G = dl5G.groupby(['MinutesCat']).sum()\n",
    "    dl5G = dl5G.add_suffix('').reset_index()\n",
    "    dl5G = dl5G.sort_values(by = 'Count', ascending=False).reset_index(drop=True)\n",
    "        \n",
    "    if len(dl5G) > 0:\n",
    "        qn.loc[i] = [n,dl5G[\"MinutesCat\"][0],dl5G[\"Count\"][0], len(dl5), \"UNFOUNDED\" ]\n",
    "\n",
    "qn[\"Mode Relative Frequency\"] = qn[\"Count of Mode\"]/qn[\"Total Number of Labor Transactions\"]\n",
    "qn[\"Mode Relative Frequency\"] = qn[\"Mode Relative Frequency\"].astype(float)\n",
    "qn[\"Mode Relative Frequency\"] = qn[\"Mode Relative Frequency\"].round(2)\n",
    "\n",
    "qn3 = qn.copy()\n",
    "\n",
    "\n",
    "frames = [qn1, qn2, qn3]\n",
    "result = pd.concat(frames).reset_index(drop=True)\n",
    "\n",
    "print (\"DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5b08237",
   "metadata": {},
   "source": [
    "### Calculate Number of People work On a Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b038227c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-12\n",
      "Calculate number of people\n",
      "21047\n",
      "21047\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "print (str(datetime.datetime.today()).split()[0] )\n",
    "\n",
    "\n",
    "print (\"Calculate number of people\")\n",
    "\n",
    "dol = dl4[[\"location\", \"Finish Date\", \"Name\", \"startdatetime\", \"finishdatetime\", \"Transaction Type\" ] ]\n",
    "\n",
    "dol = dol.sort_values(by = 'location', ascending=True).reset_index(drop=True)\n",
    "\n",
    "dol[\"Finish Date\"] = dol[\"Finish Date\"].astype(str).map(str.strip)\n",
    "dol[\"LocationDate\"] = dol[\"location\"] + \" \" + dol[\"Finish Date\"]\n",
    "\n",
    "locations = sorted(set(dol[\"location\"].tolist() ))\n",
    "\n",
    "#print (len(dol))\n",
    "#dol = dol.drop_duplicates([\"location\", \"Finish Date\", \"Name\"]).reset_index(drop=True)\n",
    "#print (len(dol))\n",
    "\n",
    "numberList = []\n",
    "nameList = []\n",
    "\n",
    "for i in range(0, len(locations)):\n",
    "#for i in range(0, 1000):\n",
    "\n",
    "    l = locations[i]\n",
    "    \n",
    "    #print (l)\n",
    "    #print (l)\n",
    "    dol2 = dol[dol[\"location\"] == l]\n",
    "    \n",
    "    dol2 = dol2.sort_values(by = 'Finish Date', ascending=True).reset_index(drop=True)\n",
    "    \n",
    "    #print (dol2)\n",
    "    #print(\"******************\")\n",
    "    \n",
    "    \n",
    "    d = sorted(set(dol2[\"Finish Date\"].tolist() ))\n",
    "    \n",
    "    #print (len(d))\n",
    "    \n",
    "    for j in range(0, len(d)):\n",
    "        dol3 = dol2[dol2[\"Finish Date\"] == d[j]].reset_index(drop=True)\n",
    "        \n",
    "        names = sorted(set(dol3[\"Name\"].tolist() ))\n",
    "        \n",
    "        \n",
    "        if (len(dol3) > 1 and len(names)>1):\n",
    "            #print (dol3)\n",
    "            #print(\"******************\")\n",
    "            #numberDic = {dol3[\"LocationDate\"][0]}\n",
    "            #numberDic[dol3[\"LocationDate\"][0]] = len(names)\n",
    "            numberList.append([dol3[\"LocationDate\"][0], len(names)])\n",
    "            nameList.append([dol3[\"LocationDate\"][0], names])\n",
    "\n",
    "\n",
    "    #print(dol2)\n",
    "    #print(\"******************\")\n",
    "    \n",
    "print (len(numberList))\n",
    "print (len(nameList))\n",
    "print (\"DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3e8a5e4",
   "metadata": {},
   "source": [
    "Create Dictionaries and Combine with Labor Transactions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "133f1f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert number on the job\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "print (\"Insert number on the job\")\n",
    "numberDict = {}\n",
    "for l2 in numberList:\n",
    "    numberDict[l2[0]] = l2[1]\n",
    "    \n",
    "nameDict = {}\n",
    "for l2 in nameList:\n",
    "    nameDict[l2[0]] = l2[1]\n",
    "    \n",
    "dl4[\"Finish Date\"] = dl4[\"Finish Date\"].astype(str).map(str.strip)\n",
    "dl4[\"LocationDate\"] = dl4[\"location\"] + \" \" + dl4[\"Finish Date\"]\n",
    "\n",
    "dl4[\"Number on Job\"] = dl4[\"LocationDate\"].map(numberDict)\n",
    "dl4[\"Employees on Job > 1\"] = dl4[\"LocationDate\"].map(nameDict)\n",
    "\n",
    "#dl4 = dl4.drop('Employees on Job', 1)\n",
    "\n",
    "dl4[\"Number on Job\"] = dl4[\"Number on Job\"].fillna(1)\n",
    "\n",
    "print (\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cafbb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cols = dl4.columns\n",
    "#cols = sorted(cols)\n",
    "#cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "911e5c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dol.to_csv(path + \"test_num_people.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48d296a9",
   "metadata": {},
   "source": [
    "### Calculate Work Time per Day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0e8f15c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "path2 = \"C:\\\\Users\\\\MehriD01\\\\Documents\\\\Pest\\\\data_dump\\\\\"\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "dl4[\"Start Date\"] = dl4[\"startdatetime\"].apply(lambda x: x.date())\n",
    "dl4[\"Start Time\"] = dl4[\"startdatetime\"]\n",
    "dl4[\"Finish Time\"] = dl4[\"finishdatetime\"]\n",
    "\n",
    "dl5 = dl4[[ \"Name\", \"Start Date\", \"Finish Date\", \"Start Time\", \"Finish Time\", \"Minutes\"]]\n",
    "\n",
    "dl5 = dl5.sort_values(by = 'Start Date', ascending=True).reset_index(drop=True)\n",
    "\n",
    "dl5[\"Start Date\"] = dl5[\"Start Date\"].astype(str).map(str.strip)\n",
    "dl5[\"Finish Date\"] = dl5[\"Finish Date\"].astype(str).map(str.strip)\n",
    "\n",
    "\n",
    "dates = sorted(list(set(dl5[\"Start Date\"].tolist() )))\n",
    "\n",
    "len(dates)\n",
    "\n",
    "\n",
    "\n",
    "dt = pd.DataFrame(columns=('Name', 'Start Date', 'Finish Date', 'Day Start Time', 'Day End Time', 'Number of Jobs', 'Minutes Worked'))\n",
    "\n",
    "all_data = pd.DataFrame()\n",
    "\n",
    "for i in range(0, len(dates)):\n",
    "#for i in range(0, 1):\n",
    "\n",
    "    #print(i)\n",
    "    dl6 = dl5[dl5[\"Start Date\"] == dates[i]]\n",
    "    dl6 = dl6[dl6[\"Finish Date\"] == dates[i]]\n",
    "    dl6 = dl6.reset_index(drop=True)\n",
    "    \n",
    "    names = list(set(dl6[\"Name\"].tolist() ))\n",
    "    \n",
    "    for j in range(0, len(names)):\n",
    "    #for j in range(0, 1):\n",
    "    \n",
    "        dl7 = dl6[dl6[\"Name\"] == names[j]]\n",
    "        \n",
    "        totalMinWorked = dl7[\"Minutes\"].sum()\n",
    "        \n",
    "        starttime = sorted(dl7[\"Start Time\"].tolist() )\n",
    "        endtime = sorted(dl7[\"Finish Time\"].tolist(),  reverse=True )\n",
    "\n",
    "\n",
    "        start = starttime[0]\n",
    "        end = endtime[0]\n",
    "        \n",
    "        #print (start)\n",
    "        #print (end)\n",
    "        \n",
    "        dt.loc[j] = [names[j],dates[i],dates[i], start, end, len(dl7), totalMinWorked]\n",
    "        \n",
    "        filename = \"work_time\" + str(i) + \".csv\"\n",
    "        \n",
    "        dt.to_csv(path2 + filename )\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "    #all_data = all_data.append(dt,ignore_index=False).reset_index(drop=True)\n",
    "    #all_data = all_data.concat(dt,ignore_index=False).reset_index(drop=True)\n",
    "\n",
    "\n",
    "#all_data = all_data.sort_values(by = 'Start Date', ascending=True).reset_index(drop=True)\n",
    "\n",
    "\n",
    "#all_data['Hours Worked'] = (all_data['Day End Time'] - all_data['Day Start Time']).dt.total_seconds()/3600\n",
    "#all_data['Minutes Worked'] = (all_data['Day End Time'] - all_data['Day Start Time']).dt.total_seconds()/60\n",
    "\n",
    "#all_data['Day Start Time'] = all_data['Day Start Time'].apply( lambda d : d.time() )\n",
    "\n",
    "#all_data['Day End Time'] = all_data['Day End Time'].apply( lambda d : d.time() )\n",
    "\n",
    "#all_data[\"Hours per Job\"] = all_data[\"Hours Worked\"]/all_data[\"Number of Jobs\"]\n",
    "#all_data[\"Minutes per Job\"] = all_data[\"Minutes Worked\"]/all_data[\"Number of Jobs\"]\n",
    "print (\"Done\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e98d434",
   "metadata": {},
   "source": [
    "Read the Data back in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1dadcbf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read files back into dataframe\n",
      "CSV files deleted successfully.\n",
      "Done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n# Now final_df contains the combined data from all CSV files\\nIn this example, you'll need to replace /path/to/csv/files/ with the actual path to the directory containing your CSV files. The glob.glob() function is used to retrieve a list of file paths matching a certain pattern (in this case, all .csv files in the specified directory).\\n\\nInside the loop, each CSV file is read into a DataFrame using pd.read_csv(file), and the resulting DataFrames are appended to the dataframes list. After the loop, the pd.concat() function is used to concatenate all the individual DataFrames into a single DataFrame named final_df.\\n\\nAlternatively, you can achieve the same result using a list comprehension:\\n\\npython\\nCopy code\\nimport pandas as pd\\nimport glob\\n\\n# Get a list of all CSV file paths in a directory\\ncsv_files = glob.glob('/path/to/csv/files/*.csv')\\n\\n# Read all CSV files into DataFrames and store them in a list comprehension\\ndataframes = [pd.read_csv(file) for file in csv_files]\\n\\n# Concatenate all DataFrames into a single DataFrame\\nfinal_df = pd.concat(dataframes, ignore_index=True)\\n\\n# Now final_df contains the combined data from all CSV files\\nBoth of these approaches will read multiple CSV files into pandas DataFrames and combine them into a single DataFrame for further analysis.\\n\\n\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "\n",
    "\n",
    "print (\"Read files back into dataframe\") \n",
    "\n",
    "# Get a list of all CSV file paths in a directory\n",
    "csv_files = glob.glob( 'C:\\\\Users\\\\MehriD01\\\\Documents\\\\Pest\\\\data_dump\\\\*.csv')\n",
    "\n",
    "# Create an empty list to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Loop through each CSV file and read it into a DataFrame\n",
    "for file in csv_files:\n",
    "    dt = pd.read_csv(file)\n",
    "    dataframes.append(dt)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "final_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "all_data = final_df.copy()\n",
    "\n",
    "subset = ['Name', 'Start Date', 'Finish Date', 'Day Start Time','Day End Time', 'Number of Jobs', 'Minutes Worked']\n",
    "\n",
    "all_data = all_data[subset]\n",
    "\n",
    "\n",
    "# Get a list of all CSV file paths in the directory\n",
    "csv_files = glob.glob(os.path.join(path2, '*.csv'))\n",
    "\n",
    "# Loop through each CSV file and delete it\n",
    "for file_path in csv_files:\n",
    "    os.remove(file_path)\n",
    "\n",
    "print(\"CSV files deleted successfully.\")\n",
    "\n",
    "\n",
    "\n",
    "print (\"Done\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cb6aa648",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nall_data[\\'Hours Worked\\'] = \"\"\\n#all_data[\\'Minutes Worked\\'] = \"\"\\n\\nfor i in range(0, len(all_data)):\\n    d = all_data[\"Day End Time\"][i] - all_data[\"Day Start Time\"][i]\\n\\n    diff = d.seconds\\n\\n    diff = int(diff)\\n    \\n    all_data[\\'Hours Worked\\'][i] = diff/3600.0\\n    #all_data[\\'Minutes Worked\\'][i] = diff/60.0\\n\\n\\n    #print (diff)\\n    \\nall_data = all_data.sort_values(by = \\'Hours Worked\\', ascending=False).reset_index(drop=True)\\n\\nall_data[\"Hours per Job\"] = all_data[\"Hours Worked\"]/all_data[\"Number of Jobs\"]\\nall_data[\"Minutes per Job\"] = all_data[\"Minutes Worked\"]/all_data[\"Number of Jobs\"]\\n'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[\"Hours Worked\"] = all_data[\"Minutes Worked\"]/60.0\n",
    "all_data[\"Hours per Job\"] = all_data[\"Hours Worked\"]/all_data[\"Number of Jobs\"]\n",
    "all_data[\"Minutes per Job\"] = all_data[\"Minutes Worked\"]/all_data[\"Number of Jobs\"]\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "all_data['Hours Worked'] = \"\"\n",
    "#all_data['Minutes Worked'] = \"\"\n",
    "\n",
    "for i in range(0, len(all_data)):\n",
    "    d = all_data[\"Day End Time\"][i] - all_data[\"Day Start Time\"][i]\n",
    "\n",
    "    diff = d.seconds\n",
    "\n",
    "    diff = int(diff)\n",
    "    \n",
    "    all_data['Hours Worked'][i] = diff/3600.0\n",
    "    #all_data['Minutes Worked'][i] = diff/60.0\n",
    "\n",
    "\n",
    "    #print (diff)\n",
    "    \n",
    "all_data = all_data.sort_values(by = 'Hours Worked', ascending=False).reset_index(drop=True)\n",
    "\n",
    "all_data[\"Hours per Job\"] = all_data[\"Hours Worked\"]/all_data[\"Number of Jobs\"]\n",
    "all_data[\"Minutes per Job\"] = all_data[\"Minutes Worked\"]/all_data[\"Number of Jobs\"]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2b331a35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46385\n",
      "31105\n"
     ]
    }
   ],
   "source": [
    "all_data2 = all_data.drop_duplicates(subset=['Name', 'Day Start Time', 'Day End Time', 'Number of Jobs']).reset_index(drop=True)\n",
    "print (len(all_data))\n",
    "print (len(all_data2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12d379e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = dl4.columns\n",
    "cols = sorted(cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97d691d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data2.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8893c069",
   "metadata": {},
   "source": [
    "Outside Normal Work Hours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "62185510",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "#all_data2[\"Day End Time\"][0].hour\n",
    "\n",
    "all_data2['Day Start Time'] = pd.to_datetime(all_data2['Day Start Time'])\n",
    "all_data2['Day End Time'] = pd.to_datetime(all_data2['Day End Time'])\n",
    "\n",
    "all_data2[\"Outside Normal Work Hours\"] = \"No\"\n",
    "\n",
    "for i in range(0, len(all_data2)):\n",
    "    if (all_data2[\"Day Start Time\"][i].hour <= 7 or all_data2[\"Day End Time\"][i].hour >= 21):\n",
    "        all_data2[\"Outside Normal Work Hours\"][i] = \"Yes\"\n",
    "        \n",
    "        \n",
    "print (\"DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d122c3e",
   "metadata": {},
   "source": [
    "### Mode: Start and End Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "20651324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "all_data2[\"Day Start Time\"][0].hour\n",
    "\n",
    "all_data2[\"Start Hour\"] = \"\"\n",
    "all_data2[\"End Hour\"] = \"\"\n",
    "\n",
    "for i in range(0, len(all_data2)):\n",
    "    all_data2[\"Start Hour\"][i] =  all_data2[\"Day Start Time\"][i].hour\n",
    "    all_data2[\"End Hour\"][i] =  all_data2[\"Day End Time\"][i].hour\n",
    "\n",
    "print (\"DONE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ee4d6a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "names = sorted(list(set(all_data2[\"Name\"].tolist()  )))\n",
    "\n",
    "qnhours = pd.DataFrame(columns=('Emplpoyee Name', 'Mode Start Time', 'Count of Start Mode', \n",
    "                                'Mode End Time', 'Count of End Mode', 'Total Number of Days Worked'))\n",
    "\n",
    "\n",
    "#dl4[\"Minutes\"] = dl4[\"Minutes\"].astype(int)\n",
    "all_data2[\"Start Hour Cat\"] = all_data2[\"Start Hour\"].astype(str)\n",
    "all_data2[\"End Hour Cat\"] = all_data2[\"End Hour\"].astype(str)\n",
    "\n",
    "\n",
    "for i in range(0, len(names)):\n",
    "    n = names[i]\n",
    "    \n",
    "  \n",
    "    all_data3 = all_data2[all_data2[\"Name\"] == n].reset_index(drop=True)\n",
    "    all_data3[\"Count\"] = 1\n",
    "    \n",
    "    #start time mode\n",
    "    all_data3G = all_data3[[\"Start Hour Cat\", \"Count\"]]\n",
    "    all_data3G = all_data3G.groupby(['Start Hour Cat']).sum()\n",
    "    all_data3G = all_data3G.add_suffix('').reset_index()\n",
    "    all_data3G = all_data3G.sort_values(by = 'Count', ascending=False).reset_index(drop=True)\n",
    "    starthourmode = all_data3G[\"Start Hour Cat\"][0]\n",
    "    starthourmodecount = all_data3G[\"Count\"][0]\n",
    "    \n",
    "    #end time mode\n",
    "    all_data3G = all_data3[[\"End Hour Cat\", \"Count\"]]\n",
    "    all_data3G = all_data3G.groupby(['End Hour Cat']).sum()\n",
    "    all_data3G = all_data3G.add_suffix('').reset_index()\n",
    "    all_data3G = all_data3G.sort_values(by = 'Count', ascending=False).reset_index(drop=True)\n",
    "    endhourmode = all_data3G[\"End Hour Cat\"][0]\n",
    "    endhourmodecount = all_data3G[\"Count\"][0]\n",
    "    \n",
    "        \n",
    "    if len(all_data3) > 0:\n",
    "        qnhours.loc[i] = [n,starthourmode, starthourmodecount,endhourmode,endhourmodecount, len(all_data3)]\n",
    "\n",
    "qnhours[\"Start Mode Relative Frequency\"] = qnhours[\"Count of Start Mode\"]/qnhours[\"Total Number of Days Worked\"]\n",
    "qnhours[\"Start Mode Relative Frequency\"] = qnhours[\"Start Mode Relative Frequency\"].astype(float)\n",
    "qnhours[\"Start Mode Relative Frequency\"] = qnhours[\"Start Mode Relative Frequency\"].round(2)\n",
    "\n",
    "qnhours[\"End Mode Relative Frequency\"] = qnhours[\"Count of End Mode\"]/qnhours[\"Total Number of Days Worked\"]\n",
    "qnhours[\"End Mode Relative Frequency\"] = qnhours[\"End Mode Relative Frequency\"].astype(float)\n",
    "qnhours[\"End Mode Relative Frequency\"] = qnhours[\"End Mode Relative Frequency\"].round(2)\n",
    "\n",
    "#qn1 = qn.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7fa1aeb",
   "metadata": {},
   "source": [
    "### Calculate the Days of the Week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "858a80fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0 = monday, 1=tuesday, 2=wednesday, 3=thursday, 4=friday, 5=saturday, 6=sunday\n",
    "dl4[\"Day\"] = dl4['Finish Time'].dt.dayofweek\n",
    "dl4[\"Day\"] = dl4[\"Day\"].astype(str).map(str.strip)\n",
    "dl4[\"Day\"] = dl4[\"Day\"].str.replace('0', 'Monday')\n",
    "dl4[\"Day\"] = dl4[\"Day\"].str.replace('1', 'Tuesday')\n",
    "dl4[\"Day\"] = dl4[\"Day\"].str.replace('2', 'Wednesday')\n",
    "dl4[\"Day\"] = dl4[\"Day\"].str.replace('3', 'Thursday')\n",
    "dl4[\"Day\"] = dl4[\"Day\"].str.replace('4', 'Friday')\n",
    "dl4[\"Day\"] = dl4[\"Day\"].str.replace('5', 'Saturday')\n",
    "dl4[\"Day\"] = dl4[\"Day\"].str.replace('6', 'Sunday')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "75f47722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DONE\n"
     ]
    }
   ],
   "source": [
    "dl4 = dl4.reset_index(drop=True)\n",
    "\n",
    "dl4['Finish Time 2'] = dl4[\"Finish Time\"].apply( lambda d : d.time() )\n",
    "dl4['Finish Time 2'] = dl4['Finish Time 2'].astype(str).map(str.strip)\n",
    "dl4['Finish Time 2'] = dl4['Finish Time 2'].str.split(\":\").str[0]\n",
    "dl4['Finish Time 2'] = dl4['Finish Time 2'].astype(int)\n",
    "\n",
    "dl4[\"Work After 4pm\"] = \"No\"\n",
    "\n",
    "for i in range(0, len(dl4)):\n",
    "    if dl4['Finish Time 2'][i] >= 16:\n",
    "        dl4[\"Work After 4pm\"][i] = \"Yes\"\n",
    "\n",
    "\n",
    "#if dl4[\"Finish Time 2\"][0] > pd.datetime('13:10:00'):\n",
    "#    print (\"hey\")\n",
    "\n",
    "print (\"DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3cc462",
   "metadata": {},
   "source": [
    "### Create Dummes for IPM Questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1143220d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create dummies\n",
      "195072\n",
      "195072\n",
      "195072\n",
      "195072\n",
      "195072\n",
      "195072\n",
      "195072\n",
      "195072\n",
      "195072\n",
      "195072\n",
      "195072\n",
      "195072\n",
      "DONE\n"
     ]
    }
   ],
   "source": [
    "print (\"Create dummies\")\n",
    "\n",
    "a = dl4[\"Was Resident Educational Literature issued\"].tolist()\n",
    "print (len(a))\n",
    "print (len(dl4))\n",
    "dummies = []\n",
    "for i in range(0, len(a)):\n",
    "    if \"N\" in a[i]:\n",
    "        dummies.append(1)\n",
    "    else:\n",
    "        dummies.append(0)       \n",
    "dl4[\"Education Literature\"] = dummies       \n",
    "\n",
    "\n",
    "a = dl4[\"Frass Removal\"].tolist()\n",
    "print (len(a))\n",
    "print (len(dl4))\n",
    "dummies = []\n",
    "for i in range(0, len(a)):\n",
    "    if \"N\" in a[i]:\n",
    "        dummies.append(1)\n",
    "    else:\n",
    "        dummies.append(0)       \n",
    "dl4[\"Frass\"] = dummies \n",
    "\n",
    "\n",
    "a = dl4[\"HEPA Vacuum\"].tolist()\n",
    "print (len(a))\n",
    "print (len(dl4))\n",
    "dummies = []\n",
    "for i in range(0, len(a)):\n",
    "    if \"N\" in a[i]:\n",
    "        dummies.append(1)\n",
    "    else:\n",
    "        dummies.append(0)       \n",
    "dl4[\"HEPA\"] = dummies\n",
    "\n",
    "\n",
    "a = dl4[\"Fill holes with excluder mesh or similar product\"].tolist()\n",
    "print (len(a))\n",
    "print (len(dl4))\n",
    "dummies = []\n",
    "for i in range(0, len(a)):\n",
    "    if \"N\" in a[i]:\n",
    "        dummies.append(1)\n",
    "    else:\n",
    "        dummies.append(0)       \n",
    "dl4[\"Exluder mesh\"] = dummies       \n",
    "\n",
    "\n",
    "a = dl4[\"Sealing\"].tolist()\n",
    "print (len(a))\n",
    "print (len(dl4))\n",
    "dummies = []\n",
    "for i in range(0, len(a)):\n",
    "    if \"N\" in a[i]:\n",
    "        dummies.append(1)\n",
    "    else:\n",
    "        dummies.append(0)       \n",
    "dl4[\"Seal\"] = dummies       \n",
    "\n",
    "a = dl4[\"Escutcheon Plate Installation\"].tolist()\n",
    "print (len(a))\n",
    "print (len(dl4))\n",
    "dummies = []\n",
    "for i in range(0, len(a)):\n",
    "    if \"N\" in a[i]:\n",
    "        dummies.append(1)\n",
    "    else:\n",
    "        dummies.append(0)      \n",
    "dl4[\"Escutcheon Plate\"] = dummies       \n",
    "\n",
    "print (\"DONE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7737fd52",
   "metadata": {},
   "source": [
    "### Create Apartment and Public Space Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f3a70cef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195072\n",
      "195072\n"
     ]
    }
   ],
   "source": [
    "locationlist = dl4[\"location\"].tolist()\n",
    "workspace = []\n",
    "for i in range(0, len(dl4)):\n",
    "    a = locationlist[i]\n",
    "    a = a.split(\".\")\n",
    "    #print (a)\n",
    "    \n",
    "    if len(a) < 5:\n",
    "        workspace.append(\"Public Space\")\n",
    "    else:\n",
    "        workspace.append(\"Apartment\")\n",
    "        \n",
    "print (len(dl4))\n",
    "print (len(workspace))\n",
    "    \n",
    "dl4[\"Work Space Type\"] =   workspace  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0602be",
   "metadata": {},
   "source": [
    "### Create Hour Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6882f3b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195072\n",
      "195072\n"
     ]
    }
   ],
   "source": [
    "#dl4[\"Hour of Day\"] = dl4[\"Finish Time\"].hour\n",
    "\n",
    "hours = dl4[\"Finish Time\"].tolist()\n",
    "\n",
    "hourofday = []\n",
    "\n",
    "for i in range(0, len(hours)):\n",
    "    #print (hours[i])\n",
    "    \n",
    "    a = hours[i].hour\n",
    "    \n",
    "    hourofday.append(a)\n",
    "    \n",
    "print (len(hourofday))\n",
    "print (len(dl4))\n",
    "\n",
    "dl4[\"Hour of Day\"] = hourofday\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b576a67",
   "metadata": {},
   "source": [
    "### Create NYCHA employee field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "19a1667f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dp = pd.read_csv(path + \"Pest Management Routes as of 1 31 23 CORRECTED.csv\")\n",
    "dp[\"Name\"] = dp[\"Name\"].astype(str).map(str.upper).map(str.strip)\n",
    "dp[\"Last Name\"] = dp[\"Name\"] .str.split(\",\").str[0].map(str.strip)\n",
    "dp[\"First Name\"] = dp[\"Name\"] .str.split(\",\").str[1].map(str.strip)\n",
    "\n",
    "dp[\"Last Name\"] = dp[\"Last Name\"].map(str.strip)\n",
    "dp[\"First Name\"] = dp[\"First Name\"].map(str.strip)\n",
    "\n",
    "dp[\"Full Name\"] = dp[\"First Name\"] + \" \" + dp[\"Last Name\"]\n",
    "\n",
    "dp[\"NYCHA Employee\"] = \"NYCHA Employee (1_31_23)\"\n",
    "\n",
    "dp[\"Full Name\"] = dp[\"Full Name\"].map(str.strip)\n",
    "\n",
    "dp[\"Full Name\"] = dp[\"Full Name\"].str.replace('AGATHA DESVIGNES-MCKAIN', 'AGATHA DESVIGNES MCKAIN')\n",
    "dp[\"Full Name\"] = dp[\"Full Name\"].str.replace('ALVEN LAKE', 'ALVIN LAKE')\n",
    "dp[\"Full Name\"] = dp[\"Full Name\"].str.replace('BRIAN JEFFRIES', 'BRIAN JEFFERIES')\n",
    "dp[\"Full Name\"] = dp[\"Full Name\"].str.replace('CELESTINE R PAYNE', 'CELESTINE PAYNE')\n",
    "dp[\"Full Name\"] = dp[\"Full Name\"].str.replace('DIEDRA EPHRAIM', 'DEIDRA EPHRAIM')\n",
    "dp[\"Full Name\"] = dp[\"Full Name\"].str.replace('DIOGENES UMANZAR', 'DIOGENES UMANZOR')\n",
    "dp[\"Full Name\"] = dp[\"Full Name\"].str.replace('GEOVANI DORSEY', 'GEOVANNIE DORSEY')\n",
    "dp[\"Full Name\"] = dp[\"Full Name\"].str.replace('HERIBERTO CANTRES', 'HERIBERTO CANTES')\n",
    "dp[\"Full Name\"] = dp[\"Full Name\"].str.replace('JEMEEL TUCKER', 'JAMEEL TUCKER')\n",
    "dp[\"Full Name\"] = dp[\"Full Name\"].str.replace('JOSEPH UPSUR', 'JOSEPH UPSHUR')\n",
    "dp[\"Full Name\"] = dp[\"Full Name\"].str.replace('LAYR DORZIN', 'LAYR DORZIN, JR')\n",
    "dp[\"Full Name\"] = dp[\"Full Name\"].str.replace('LENAIR DANIELS', 'LENAIR DANIEL')\n",
    "dp[\"Full Name\"] = dp[\"Full Name\"].str.replace('LORRAINE LOWERY- CLARK', 'LORRAINE LOWERY-CLARK')\n",
    "dp[\"Full Name\"] = dp[\"Full Name\"].str.replace('MATTEW MARTINEZ', 'MATTHEW MARTINEZ')\n",
    "dp[\"Full Name\"] = dp[\"Full Name\"].str.replace('NUDUKA OKORO', 'NDUKA OKORO')\n",
    "dp[\"Full Name\"] = dp[\"Full Name\"].str.replace('OLUYINKA ODUMNBAKU', 'OLUYINKA ODUNMBAKU')\n",
    "dp[\"Full Name\"] = dp[\"Full Name\"].str.replace('SALVATORE CASTELLENO', 'SALVATORE CASTELLANO')\n",
    "dp[\"Full Name\"] = dp[\"Full Name\"].str.replace('SHERIF RASHID', 'SHAREEF RASHID')\n",
    "dp[\"Full Name\"] = dp[\"Full Name\"].str.replace('SHANICE CALLWOOD', 'SHAUNICE CALLWOOD')\n",
    "dp[\"Full Name\"] = dp[\"Full Name\"].str.replace('SOLOMON SOOKOO', 'SOLOMAN SOOKOO')\n",
    "\n",
    "dp[\"Full Name\"] = dp[\"Full Name\"].str.replace('VICAS FRANCIS', 'VICKAS FRANCIS')\n",
    "\n",
    "\n",
    "dpDic = dp.set_index('Full Name')['NYCHA Employee'].to_dict()\n",
    "\n",
    "dpList = dp[\"Full Name\"].tolist()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df24657f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "dln = dl4[[\"Name\"]]\n",
    "dln[\"Name\"] = dln[\"Name\"].astype(str).map(str.upper).map(str.strip)\n",
    "dln = dln.drop_duplicates(['Name']).reset_index(drop=True)\n",
    "\n",
    "dln[\"NYCHA Employee\"] = dln[\"Name\"].map(dpDic)\n",
    "\n",
    "dln = dln.sort_values(by = 'Name', ascending=True).reset_index(drop=True)\n",
    "\n",
    "dlnList = dln[\"Name\"].tolist()\n",
    "\n",
    "#dln.to_csv(path + \"test_names.csv\", index=False)\n",
    "\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "from operator import itemgetter\n",
    "\n",
    "\n",
    "def fuzzy_match(string1, string2):\n",
    "    \n",
    "    #Compares two strings using fuzzy matching and returns a score between 0 and 100.\n",
    "\n",
    "    return fuzz.ratio(string1, string2)\n",
    "\n",
    "dln[\"NYCHA Employee\"] = dln[\"NYCHA Employee\"].astype(str)\n",
    "dln[\"Fuzzy Name Closest Match\"] = \"\"\n",
    "dln[\"Fuzzy Score\"] = \"\"\n",
    "\n",
    "for i in range(0, len(dln)):\n",
    "    if dln[\"NYCHA Employee\"][i]=='nan' :\n",
    "        n = dln[\"Name\"][i]\n",
    "        #print (n)\n",
    "        \n",
    "        namematch = []\n",
    "\n",
    "        for j in range(0, len(dpList)):\n",
    "            #print (dpList[j], fuzzy_match(n, dpList[j]))\n",
    "            namematch.append([dpList[j], fuzzy_match(n, dpList[j])])\n",
    "            \n",
    "            namematch = sorted(namematch, key=itemgetter(1), reverse=True)\n",
    "\n",
    "        dln[\"Fuzzy Name Closest Match\"][i] = namematch[0][0]\n",
    "        dln[\"Fuzzy Score\"][i] = namematch[0][1]\n",
    "\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf80a593",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dln.to_csv(path + \"test_names.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a6ed7a",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "db13e4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data2.to_csv(path + \"Work Time Analytics.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fb001241",
   "metadata": {},
   "outputs": [],
   "source": [
    "qnhours.to_csv(path + \"Start and End Time Modes.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "da277225",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv(path + \"Time Mode and Employee Names.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "74fe7146",
   "metadata": {},
   "outputs": [],
   "source": [
    "dl4.to_csv(path + \"Pest Labor Transactions.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cc1959e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dl4.to_csv(path + \"test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290cbf05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
